"""
Demonstration script for the integrated Japanese/English lipogram generator.
çµ±åˆæ—¥æœ¬èªãƒ»è‹±èªãƒªãƒã‚°ãƒ©ãƒ ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
"""

import sys
import os
import time

# Add the project root to the Python path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))


def print_header(title: str):
    """Print a formatted header."""
    print("\n" + "=" * 60)
    print(f"  {title}")
    print("=" * 60)


def print_section(title: str):
    """Print a formatted section header."""
    print(f"\nğŸ”¹ {title}")
    print("-" * 40)


def demo_japanese():
    """Demonstrate Japanese lipogram generation."""
    print_header("æ—¥æœ¬èªãƒªãƒã‚°ãƒ©ãƒ ç”Ÿæˆãƒ‡ãƒ¢")

    try:
        from ripogram.core.rewriter import RipogramRewriter
        from ripogram.config import Config

        print("âœ… æ—¥æœ¬èªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®èª­ã¿è¾¼ã¿æˆåŠŸ")

        # Check API key
        try:
            config = Config()
            if not config.openai_api_key:
                print("âŒ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                print("ğŸ’¡ .envãƒ•ã‚¡ã‚¤ãƒ«ã«OPENAI_API_KEYã‚’è¨­å®šã—ã¦ãã ã•ã„")
                return
            print("âœ… OpenAI APIã‚­ãƒ¼è¨­å®šç¢ºèªæ¸ˆã¿")
        except Exception as e:
            print(f"âŒ è¨­å®šã‚¨ãƒ©ãƒ¼: {e}")
            return

        # Demo examples
        examples = [
            {
                "text": "å¾è¼©ã¯çŒ«ã§ã‚ã‚‹ã€‚",
                "banned": ["ã„"],
                "description": "å¤ç›®æ¼±çŸ³ã€Œå¾è¼©ã¯çŒ«ã§ã‚ã‚‹ã€- 'ã„'ã‚’é¿ã‘ã‚‹"
            },
            {
                "text": "ä»Šæ—¥ã¯è‰¯ã„å¤©æ°—ã§ã™ã€‚",
                "banned": ["ã„", "ã¦"],
                "description": "æ—¥å¸¸ä¼šè©± - 'ã„'ã¨'ã¦'ã‚’é¿ã‘ã‚‹"
            }
        ]

        for i, example in enumerate(examples, 1):
            print_section(f"ä¾‹ {i}: {example['description']}")
            print(f"å…¥åŠ›æ–‡: {example['text']}")
            print(f"ç¦æ­¢æ–‡å­—: {', '.join(example['banned'])}")

            print("ğŸ¤– GPTã§å¤‰æ›ä¸­...")
            print("ğŸ’¡ å®Ÿéš›ã®å¤‰æ›ã«ã¯APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™")
            print("ğŸ“ ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰: å¤‰æ›å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")

    except ImportError as e:
        print(f"âŒ æ—¥æœ¬èªãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        print("ğŸ’¡ å¿…è¦ãªä¾å­˜é–¢ä¿‚ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„: pip install openai")


def demo_english():
    """Demonstrate English lipogram generation."""
    print_header("English Lipogram Generation Demo")

    try:
        from ripogram.core.english_bert_rewriter import EnglishBertRewriter
        from ripogram.core.english_tokenizer import EnglishTokenizer

        print("âœ… English modules loaded successfully")

        # Test tokenizer first
        print_section("WordNet Synonym Test")
        tokenizer = EnglishTokenizer()

        test_words = ["happy", "quick", "cat", "run"]
        for word in test_words:
            synonyms = tokenizer.get_synonyms(word)
            print(f"'{word}' synonyms: {', '.join(synonyms[:5])}...")

        print_section("BERT Model Loading Test")
        print("ğŸ”„ Loading BERT model (this may take a moment)...")

        try:
            rewriter = EnglishBertRewriter("bert-base-uncased")
            print("âœ… BERT model loaded successfully")

            # Demo examples
            examples = [
                {
                    "text": "The cat sat on the mat.",
                    "banned": ["e"],
                    "description": "Classic 'no E' lipogram"
                },
                {
                    "text": "Hello world!",
                    "banned": ["l", "o"],
                    "description": "Avoiding 'l' and 'o'"
                }
            ]

            for i, example in enumerate(examples, 1):
                print_section(f"Example {i}: {example['description']}")
                print(f"Input: {example['text']}")
                print(f"Banned chars: {', '.join(example['banned'])}")

                try:
                    print("ğŸ”„ Generating lipogram...")
                    start_time = time.time()

                    result = rewriter.rewrite_text(
                        example["text"],
                        example["banned"],
                        similarity_threshold=0.4,
                        verbose=False
                    )

                    processing_time = time.time() - start_time

                    print(f"âœ¨ Result: {result}")
                    print(f"â±ï¸  Processing time: {processing_time:.2f}s")

                    # Verify result
                    banned_found = []
                    for char in example["banned"]:
                        if char.lower() in result.lower():
                            banned_found.append(char)

                    if banned_found:
                        print(
                            f"âš ï¸  Warning: Still contains: {', '.join(banned_found)}")
                    else:
                        print("âœ… Success: No banned characters found")

                except Exception as e:
                    print(f"âŒ Generation error: {e}")

        except Exception as e:
            print(f"âŒ BERT model loading error: {e}")
            print("ğŸ’¡ Make sure PyTorch and transformers are installed")
            print("ğŸ’¡ First run may take time to download models")

    except ImportError as e:
        print(f"âŒ English module import error: {e}")
        print("ğŸ’¡ Install required dependencies:")
        print("   pip install torch transformers nltk spacy scikit-learn")
        print("   python -m spacy download en_core_web_sm")


def demo_integrated_features():
    """Demonstrate integrated system features."""
    print_header("çµ±åˆã‚·ã‚¹ãƒ†ãƒ æ©Ÿèƒ½ãƒ‡ãƒ¢")

    print_section("Available Interfaces")
    interfaces = [
        ("CLI (Japanese)", "python -m ripogram.cli"),
        ("CLI (English)", "python -m ripogram.english_cli --interactive"),
        ("Web App (Japanese)", "streamlit run streamlit_app.py"),
        ("Web App (English)", "streamlit run english_streamlit_app.py"),
        ("Integrated Web App", "streamlit run integrated_streamlit_app.py"),
    ]

    for name, command in interfaces:
        print(f"ğŸ“± {name}")
        print(f"   Command: {command}")

    print_section("Test Suites")
    test_files = [
        ("Japanese Tests", "python test_ripogram.py"),
        ("English Tests", "python test_english_ripogram.py"),
        ("Integration Demo", "python demo_integrated.py")
    ]

    for name, command in test_files:
        print(f"ğŸ§ª {name}")
        print(f"   Command: {command}")

    print_section("Research Documentation")
    docs = [
        ("Research Slides", "ä¸­é–“ç™ºè¡¨ãƒªãƒã‚°ãƒ©ãƒ .pptx.pdf"),
        ("Japanese README", "README.md"),
        ("English README", "README_ENGLISH.md"),
        ("Requirements", "requirements.txt")
    ]

    for name, file in docs:
        if os.path.exists(file):
            print(f"ğŸ“„ {name}: âœ… {file}")
        else:
            print(f"ğŸ“„ {name}: âŒ {file} (not found)")


def main():
    """Main demonstration function."""
    print("ğŸŒ çµ±åˆãƒªãƒã‚°ãƒ©ãƒ ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ  ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("   Integrated Lipogram Generation System Demonstration")
    print(f"   Author: æ©‹æœ¬ è‘µ (Aoi Hashimoto) - 22G1104002B")
    print(f"   Institution: ä¸­å¤®å¤§å­¦å›½éš›æƒ…å ±å­¦éƒ¨")

    # Check Python version
    python_version = sys.version_info
    print(
        f"ğŸ Python Version: {python_version.major}.{python_version.minor}.{python_version.micro}")

    if python_version < (3, 8):
        print("âš ï¸  Warning: Python 3.8+ recommended")

    # Demo menu
    while True:
        print_header("ãƒ‡ãƒ¢ãƒ¡ãƒ‹ãƒ¥ãƒ¼ / Demo Menu")
        options = [
            ("1", "æ—¥æœ¬èªãƒªãƒã‚°ãƒ©ãƒ ç”Ÿæˆãƒ‡ãƒ¢ (Japanese Demo)"),
            ("2", "English Lipogram Generation Demo"),
            ("3", "çµ±åˆã‚·ã‚¹ãƒ†ãƒ æ©Ÿèƒ½ç´¹ä»‹ (Integrated Features)"),
            ("4", "ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶ç¢ºèª (System Requirements)"),
            ("q", "çµ‚äº† (Quit)")
        ]

        for key, desc in options:
            print(f"  {key}. {desc}")

        choice = input("\né¸æŠã—ã¦ãã ã•ã„ (Enter your choice): ").strip().lower()

        if choice == "1":
            demo_japanese()
        elif choice == "2":
            demo_english()
        elif choice == "3":
            demo_integrated_features()
        elif choice == "4":
            check_system_requirements()
        elif choice in ["q", "quit", "exit"]:
            print("\nğŸ‘‹ ãƒ‡ãƒ¢ã‚’çµ‚äº†ã—ã¾ã™ã€‚ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸï¼")
            print("   Thank you for trying the demo!")
            break
        else:
            print("âŒ ç„¡åŠ¹ãªé¸æŠã§ã™ã€‚ã‚‚ã†ä¸€åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
            print("   Invalid choice. Please try again.")


def check_system_requirements():
    """Check system requirements and dependencies."""
    print_header("ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶ç¢ºèª")

    print_section("Python Packages")
    required_packages = [
        ("openai", "OpenAI API client"),
        ("fugashi", "Japanese morphological analyzer"),
        ("python-dotenv", "Environment variable loader"),
        ("streamlit", "Web application framework"),
        ("torch", "PyTorch for BERT models"),
        ("transformers", "Hugging Face transformers"),
        ("nltk", "Natural Language Toolkit"),
        ("spacy", "Advanced NLP processing"),
        ("scikit-learn", "Machine learning utilities")
    ]

    for package, description in required_packages:
        try:
            __import__(package)
            print(f"âœ… {package}: {description}")
        except ImportError:
            print(f"âŒ {package}: {description} (not installed)")

    print_section("NLTK Data")
    try:
        import nltk
        nltk_data = ["punkt", "averaged_perceptron_tagger", "wordnet"]
        for data in nltk_data:
            try:
                nltk.data.find(f"tokenizers/{data}")
                print(f"âœ… NLTK {data}")
            except LookupError:
                try:
                    nltk.data.find(f"taggers/{data}")
                    print(f"âœ… NLTK {data}")
                except LookupError:
                    try:
                        nltk.data.find(f"corpora/{data}")
                        print(f"âœ… NLTK {data}")
                    except LookupError:
                        print(f"âŒ NLTK {data} (not downloaded)")
    except ImportError:
        print("âŒ NLTK not available")

    print_section("spaCy Models")
    try:
        import spacy
        try:
            spacy.load("en_core_web_sm")
            print("âœ… spaCy English model (en_core_web_sm)")
        except OSError:
            print(
                "âŒ spaCy English model (en_core_web_sm) - run: python -m spacy download en_core_web_sm")
    except ImportError:
        print("âŒ spaCy not available")

    print_section("Configuration Files")
    config_files = [
        (".env", "Environment variables"),
        (".env.example", "Environment template"),
        ("requirements.txt", "Python dependencies")
    ]

    for file, desc in config_files:
        if os.path.exists(file):
            print(f"âœ… {file}: {desc}")
        else:
            print(f"âŒ {file}: {desc} (not found)")


if __name__ == "__main__":
    main()

"""
Integrated Streamlit Web Application for Lipogram Generation
æ—¥æœ¬èªãƒ»è‹±èªãƒªãƒã‚°ãƒ©ãƒ ç”Ÿæˆã®ãŸã‚ã®çµ±åˆWebã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
"""

import streamlit as st
import sys
import os
import time
import traceback
import base64
from pathlib import Path
from typing import List

# Add the current directory to Python path for imports
sys.path.insert(0, '.')

try:
    # Japanese version imports
    from ripogram.core.rewriter import RipogramRewriter
    from ripogram.config import Config

    # English version imports
    from ripogram.core.english_bert_rewriter import EnglishBertRewriter
    from ripogram.core.english_tokenizer import EnglishTokenizer

    IMPORTS_AVAILABLE = True
except ImportError as e:
    IMPORTS_AVAILABLE = False
    IMPORT_ERROR = str(e)


# Page configuration
st.set_page_config(
    page_title="çµ±åˆãƒªãƒã‚°ãƒ©ãƒ ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼",
    page_icon="ğŸŒ",
    layout="wide",
    initial_sidebar_state="expanded"
)


def initialize_session_state():
    """Initialize session state variables."""
    if 'current_page' not in st.session_state:
        st.session_state.current_page = 'Japanese'
    if 'japanese_rewriter' not in st.session_state:
        st.session_state.japanese_rewriter = None
    if 'english_rewriter' not in st.session_state:
        st.session_state.english_rewriter = None
    if 'english_model_loaded' not in st.session_state:
        st.session_state.english_model_loaded = False
    if 'history' not in st.session_state:
        st.session_state.history = []
    if 'show_pdf_slideshow' not in st.session_state:
        st.session_state.show_pdf_slideshow = False


def parse_banned_chars(banned_chars_str: str) -> List[str]:
    """Parse banned characters string into list."""
    if not banned_chars_str.strip():
        return []
    # Support both comma and space separation
    if ',' in banned_chars_str:
        return [char.strip() for char in banned_chars_str.split(",")]
    else:
        return banned_chars_str.split()


def load_english_model(model_name: str):
    """Load English BERT model with caching."""
    if st.session_state.english_rewriter is None or not st.session_state.english_model_loaded:
        with st.spinner(f"Loading BERT model: {model_name}..."):
            try:
                st.session_state.english_rewriter = EnglishBertRewriter(
                    model_name)
                st.session_state.english_model_loaded = True
                st.success("âœ… BERT model loaded successfully!")
                return True
            except Exception as e:
                st.error(f"âŒ Error loading BERT model: {e}")
                return False
    return True


def verify_lipogram(text: str, banned_chars: List[str]) -> tuple:
    """
    Verify if text is a valid lipogram.

    Returns:
        tuple: (is_valid, banned_chars_found)
    """
    banned_found = []
    for char in banned_chars:
        if char.lower() in text.lower():
            banned_found.append(char)

    return len(banned_found) == 0, banned_found


def display_token_analysis(text: str, banned_chars: List[str], language: str):
    """Display token analysis in an expandable section."""
    with st.expander("ğŸ” Token Analysis", expanded=False):
        if language == 'English':
            tokenizer = EnglishTokenizer()
            tokens = tokenizer.tokenize(text)
        else:
            # For Japanese, we'll use a simple character-based analysis
            tokens = [{'surface': char} for char in text if char.strip()]

        st.write(f"**Total tokens:** {len(tokens)}")

        # Create columns for better layout
        col1, col2 = st.columns(2)

        with col1:
            st.write("**Valid tokens:**")
            valid_tokens = []
            for token in tokens:
                surface = token['surface']
                if not any(char.lower() in surface.lower() for char in banned_chars):
                    valid_tokens.append(surface)

            if valid_tokens:
                st.write(", ".join(valid_tokens[:20]))  # Show first 20
                if len(valid_tokens) > 20:
                    st.write(f"... and {len(valid_tokens) - 20} more")
            else:
                st.write("None")

        with col2:
            st.write("**Tokens with banned characters:**")
            invalid_tokens = []
            for token in tokens:
                surface = token['surface']
                if any(char.lower() in surface.lower() for char in banned_chars):
                    invalid_tokens.append(surface)

            if invalid_tokens:
                st.write(", ".join(invalid_tokens[:20]))  # Show first 20
                if len(invalid_tokens) > 20:
                    st.write(f"... and {len(invalid_tokens) - 20} more")
            else:
                st.write("None")


def show_pdf_slideshow():
    """Display PDF as a slideshow with navigation."""
    st.title("ğŸ“ ç ”ç©¶ç™ºè¡¨ã‚¹ãƒ©ã‚¤ãƒ‰ã‚·ãƒ§ãƒ¼")
    st.markdown("**ä¸­å¤®å¤§å­¦å›½éš›æƒ…å ±å­¦éƒ¨ï¼”å¹´ | 22G1104002B æ©‹æœ¬ è‘µ**")

    # Initialize session state for slide navigation
    if 'current_slide' not in st.session_state:
        st.session_state.current_slide = 1

    total_slides = 16  # Total number of slides in the PDF

    # Navigation controls
    col1, col2, col3, col4, col5 = st.columns([1, 1, 2, 1, 1])

    with col1:
        if st.button("â®ï¸ æœ€åˆ", help="æœ€åˆã®ã‚¹ãƒ©ã‚¤ãƒ‰ã«ç§»å‹•"):
            st.session_state.current_slide = 1
            st.rerun()

    with col2:
        if st.button("â—€ï¸ å‰", help="å‰ã®ã‚¹ãƒ©ã‚¤ãƒ‰ã«ç§»å‹•"):
            if st.session_state.current_slide > 1:
                st.session_state.current_slide -= 1
                st.rerun()

    with col3:
        st.markdown(
            f"**ã‚¹ãƒ©ã‚¤ãƒ‰: {st.session_state.current_slide} / {total_slides}**")

    with col4:
        if st.button("â–¶ï¸ æ¬¡", help="æ¬¡ã®ã‚¹ãƒ©ã‚¤ãƒ‰ã«ç§»å‹•"):
            if st.session_state.current_slide < total_slides:
                st.session_state.current_slide += 1
                st.rerun()

    with col5:
        if st.button("â­ï¸ æœ€å¾Œ", help="æœ€å¾Œã®ã‚¹ãƒ©ã‚¤ãƒ‰ã«ç§»å‹•"):
            st.session_state.current_slide = total_slides
            st.rerun()

    # Display PDF
    pdf_path = Path("docs/ä¸­é–“ç™ºè¡¨ãƒªãƒã‚°ãƒ©ãƒ .pdf")

    if pdf_path.exists():
        try:
            with open(pdf_path, "rb") as f:
                pdf_data = f.read()

            pdf_base64 = base64.b64encode(pdf_data).decode('utf-8')

            # Display PDF
            pdf_display = f"""
            <div style="width: 100%; max-width: 900px; margin: 0 auto;">
                <div style="position: relative; width: 100%; padding-bottom: 70.7%; border: 1px solid #ddd; border-radius: 10px; overflow: hidden; box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);">
                    <iframe 
                        src="data:application/pdf;base64,{pdf_base64}#page={st.session_state.current_slide}&toolbar=1&navpanes=0&scrollbar=0&view=Fit" 
                        style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border: none;"
                        type="application/pdf">
                        <p>PDFã‚’è¡¨ç¤ºã§ãã¾ã›ã‚“ã€‚ãƒ–ãƒ©ã‚¦ã‚¶ãŒPDFè¡¨ç¤ºã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚</p>
                    </iframe>
                </div>
            </div>
            """

            st.markdown(pdf_display, unsafe_allow_html=True)

            # Close slideshow button
            if st.button("âŒ ã‚¹ãƒ©ã‚¤ãƒ‰ã‚·ãƒ§ãƒ¼ã‚’é–‰ã˜ã‚‹", type="secondary"):
                st.session_state.show_pdf_slideshow = False
                st.rerun()

        except Exception as e:
            st.error(f"âŒ PDFã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
    else:
        st.error("âŒ PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: ä¸­é–“ç™ºè¡¨ãƒªãƒã‚°ãƒ©ãƒ .pdf")


def japanese_page():
    """Japanese lipogram generation page."""
    st.title("ğŸ“ æ—¥æœ¬èªãƒªãƒã‚°ãƒ©ãƒ ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼")
    st.markdown("""
    **ãƒªãƒã‚°ãƒ©ãƒ ï¼ˆLipogramï¼‰** ã¨ã¯ã€ç‰¹å®šã®æ–‡å­—ã‚’ä½¿ã‚ãšã«æ–‡ç« ã‚’æ›¸ãè¨€è‘‰éŠã³ã§ã™ã€‚
    ã“ã®ãƒšãƒ¼ã‚¸ã§ã¯ã€AIï¼ˆGPT-4ï¼‰ã‚’ä½¿ã£ã¦æ—¥æœ¬èªã®æ–‡ç« ã‹ã‚‰æŒ‡å®šã—ãŸæ–‡å­—ã‚’é™¤ã„ãŸè‡ªç„¶ãªæ–‡ç« ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
    """)

    # Settings in sidebar
    with st.sidebar:
        st.header("âš™ï¸ æ—¥æœ¬èªè¨­å®š")

        # Model selection
        model_options = [
            "gpt-4.1-nano",
            "gpt-4o-mini",
            "gpt-4",
            "gpt-4-turbo",
            "gpt-3.5-turbo"
        ]
        selected_model = st.selectbox(
            "ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«",
            model_options,
            index=0,
            help="ä½¿ç”¨ã™ã‚‹OpenAI GPTãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„"
        )

        # Verbose mode
        verbose_mode = st.checkbox(
            "è©³ç´°è¡¨ç¤ºãƒ¢ãƒ¼ãƒ‰",
            value=False,
            help="å¤‰æ›éç¨‹ã®è©³ç´°ã‚’è¡¨ç¤ºã—ã¾ã™"
        )

        # API key status
        st.markdown("---")
        st.markdown("**APIè¨­å®šçŠ¶æ³:**")
        try:
            config = Config()
            if config.openai_api_key:
                st.success("âœ… OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™")
            else:
                st.error("âŒ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        except Exception as e:
            st.error(f"âŒ è¨­å®šã‚¨ãƒ©ãƒ¼: {str(e)}")

    # Main input area
    st.header("ğŸ“ å…¥åŠ›")

    # Initialize session state for examples
    if 'jp_example_text' not in st.session_state:
        st.session_state.jp_example_text = ""
    if 'jp_example_banned' not in st.session_state:
        st.session_state.jp_example_banned = ""

    # Example buttons
    st.markdown("**ä½¿ç”¨ä¾‹:** ä»¥ä¸‹ã®ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ã¨ã€å…¥åŠ›æ¬„ã«ä¾‹æ–‡ãŒè‡ªå‹•å…¥åŠ›ã•ã‚Œã¾ã™")
    col1, col2, col3 = st.columns(3)

    with col1:
        if st.button("ä¾‹1: åŸºæœ¬çš„ãªä¾‹", help="å¤ç›®æ¼±çŸ³ã€Œå¾è¼©ã¯çŒ«ã§ã‚ã‚‹ã€å†’é ­æ–‡"):
            st.session_state.jp_example_text = "å¾è¼©ã¯çŒ«ã§ã‚ã‚‹ã€‚"
            st.session_state.jp_example_banned = "ã„"

    with col2:
        if st.button("ä¾‹2: è¤‡æ•°æ–‡", help="æœ‰åãªã“ã¨ã‚ã–2ã¤ã‚’çµ„ã¿åˆã‚ã›ãŸä¾‹"):
            st.session_state.jp_example_text = "çŒ¿ã‚‚æœ¨ã‹ã‚‰è½ã¡ã‚‹ã€‚çŸ³ã®ä¸Šã«ã‚‚ä¸‰å¹´ã€‚"
            st.session_state.jp_example_banned = "ã„,ã•"

    with col3:
        if st.button("ä¾‹3: å³ã—ã„åˆ¶ç´„", help="å·ç«¯åº·æˆã€Œé›ªå›½ã€å†’é ­æ–‡ã§ã®é›£ã—ã„ä¾‹"):
            st.session_state.jp_example_text = "å›½å¢ƒã®é•·ã„ãƒˆãƒ³ãƒãƒ«ã‚’æŠœã‘ã‚‹ã¨é›ªå›½ã§ã‚ã£ãŸã€‚"
            st.session_state.jp_example_banned = "ã„,ã¨,ã¬,ã‚†"

    # Text input
    input_text = st.text_area(
        "å¤‰æ›ã—ãŸã„æ–‡ç« ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:",
        value=st.session_state.jp_example_text,
        height=150,
        placeholder="ä¾‹: ä»Šæ—¥ã¯è‰¯ã„å¤©æ°—ã§ã™ã€‚å…¬åœ’ã§çŒ«ã¨çŠ¬ãŒéŠã‚“ã§ã„ã¾ã™ã€‚",
        help="è¤‡æ•°ã®æ–‡ç« ã‚’å…¥åŠ›ã§ãã¾ã™ã€‚å¥ç‚¹ã§è‡ªå‹•çš„ã«æ–‡å˜ä½ã§å‡¦ç†ã•ã‚Œã¾ã™ã€‚"
    )

    # Banned characters input
    banned_chars_input = st.text_input(
        "ç¦æ­¢æ–‡å­—ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰:",
        value=st.session_state.jp_example_banned,
        placeholder="ä¾‹: ã„,ã—,ãŸ",
        help="ä½¿ç”¨ã‚’ç¦æ­¢ã™ã‚‹æ–‡å­—ã‚’ã‚«ãƒ³ãƒã§åŒºåˆ‡ã£ã¦å…¥åŠ›ã—ã¦ãã ã•ã„"
    )

    # Clear button
    if st.button("ğŸ—‘ï¸ å…¥åŠ›ã‚’ã‚¯ãƒªã‚¢", help="å…¥åŠ›æ¬„ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã™"):
        st.session_state.jp_example_text = ""
        st.session_state.jp_example_banned = ""
        st.rerun()

    # Generate button
    if st.button("ğŸš€ ãƒªãƒã‚°ãƒ©ãƒ ç”Ÿæˆ", type="primary", use_container_width=True):
        if not input_text.strip():
            st.error("âŒ æ–‡ç« ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return

        if not banned_chars_input.strip():
            st.error("âŒ ç¦æ­¢æ–‡å­—ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return

        # Parse banned characters
        banned_chars = parse_banned_chars(banned_chars_input)

        if not banned_chars:
            st.error("âŒ æœ‰åŠ¹ãªç¦æ­¢æ–‡å­—ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            return

        # Show processing message
        with st.spinner(f"ğŸ¤– {selected_model}ã§å¤‰æ›ä¸­..."):
            try:
                # Load configuration
                config = Config()
                config.model_name = selected_model

                # Initialize rewriter
                rewriter = RipogramRewriter(
                    api_key=config.openai_api_key,
                    model_name=config.model_name
                )

                # Display processing info
                st.info(f"ğŸ“Š å‡¦ç†æƒ…å ±: ãƒ¢ãƒ‡ãƒ«={selected_model}, ç¦æ­¢æ–‡å­—={banned_chars}")

                if verbose_mode:
                    # Create a container for verbose output
                    verbose_container = st.container()

                    # Capture verbose output
                    import io
                    from contextlib import redirect_stdout

                    output_buffer = io.StringIO()

                    with redirect_stdout(output_buffer):
                        result = rewriter.rewrite_text_with_context(
                            text=input_text,
                            banned_chars=banned_chars,
                            verbose=True
                        )

                    # Display verbose output
                    verbose_output = output_buffer.getvalue()
                    if verbose_output:
                        with verbose_container:
                            st.subheader("ğŸ” å¤‰æ›éç¨‹ã®è©³ç´°")
                            st.code(verbose_output, language="text")
                else:
                    # Process without verbose output
                    result = rewriter.rewrite_text_with_context(
                        text=input_text,
                        banned_chars=banned_chars,
                        verbose=False
                    )

                # Display results
                st.subheader("ğŸŸ¢ å¤‰æ›çµæœ")

                # Display original and result side by side
                col1, col2 = st.columns(2)

                with col1:
                    st.markdown("**å…ƒã®æ–‡ç« :**")
                    st.markdown(f"""
                    <div style="background-color: #f0f2f6; padding: 15px; border-radius: 10px; border-left: 5px solid #ff6b6b;">
                    <p style="margin: 0; font-size: 16px; line-height: 1.6; color: #333;">{input_text}</p>
                    </div>
                    """, unsafe_allow_html=True)

                with col2:
                    st.markdown("**å¤‰æ›å¾Œ:**")
                    st.markdown(f"""
                    <div style="background-color: #e8f5e8; padding: 15px; border-radius: 10px; border-left: 5px solid #4caf50;">
                    <p style="margin: 0; font-size: 16px; line-height: 1.6; color: #333; font-weight: 500;">{result}</p>
                    </div>
                    """, unsafe_allow_html=True)

                # Display statistics
                st.markdown("**çµ±è¨ˆæƒ…å ±:**")
                col1, col2, col3 = st.columns(3)

                with col1:
                    st.metric("å…ƒã®æ–‡å­—æ•°", len(input_text))
                with col2:
                    st.metric("å¤‰æ›å¾Œæ–‡å­—æ•°", len(result))
                with col3:
                    st.metric("ç¦æ­¢æ–‡å­—æ•°", len(banned_chars))

                # Success message
                st.success("âœ… å¤‰æ›ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

                # Add to history
                st.session_state.history.append({
                    'language': 'Japanese',
                    'input': input_text,
                    'banned_chars': banned_chars,
                    'result': result,
                    'model': selected_model
                })

            except ValueError as e:
                st.error(f"âŒ è¨­å®šã‚¨ãƒ©ãƒ¼: {str(e)}")
                st.info("ğŸ’¡ .envãƒ•ã‚¡ã‚¤ãƒ«ã«OpenAI APIã‚­ãƒ¼ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

            except Exception as e:
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                if st.checkbox("è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’è¡¨ç¤º"):
                    st.code(traceback.format_exc())


def english_page():
    """English lipogram generation page."""
    st.title("ğŸ¯ English Lipogram Generator")
    st.markdown("""
    **Lipogram** is a form of constrained writing where certain letters are deliberately avoided.
    This page uses BERT + WordNet approach to generate English lipograms by replacing words containing banned characters with semantically similar alternatives.
    """)

    # Settings in sidebar
    with st.sidebar:
        st.header("âš™ï¸ English Settings")

        # Model selection
        model_options = {
            "BERT Base (Uncased)": "bert-base-uncased",
            "BERT Large (Uncased)": "bert-large-uncased",
            "DistilBERT": "distilbert-base-uncased"
        }

        selected_model_name = st.selectbox(
            "Select BERT Model:",
            options=list(model_options.keys()),
            index=0
        )
        model_name = model_options[selected_model_name]

        # Similarity threshold
        similarity_threshold = st.slider(
            "Similarity Threshold:",
            min_value=0.0,
            max_value=1.0,
            value=0.5,
            step=0.1,
            help="Minimum similarity score for word replacements"
        )

        # Verbose output
        verbose_output = st.checkbox(
            "Show Detailed Processing",
            value=False,
            help="Display detailed token processing information"
        )

        # Load model
        if st.button("ğŸ”„ Load/Reload Model"):
            st.session_state.english_model_loaded = False
            st.session_state.english_rewriter = None

        if not st.session_state.english_model_loaded:
            if not load_english_model(model_name):
                st.stop()

        # Display synonym examples
        st.markdown("### ğŸ“š WordNet Synonym Examples")

        tokenizer = EnglishTokenizer()
        example_words = ["happy", "quick", "run", "beautiful", "house"]

        for word in example_words:
            synonyms = tokenizer.get_synonyms(word)
            if synonyms:
                with st.expander(f"'{word}' synonyms"):
                    st.write(", ".join(synonyms[:8]))

    # Main input area
    st.header("ğŸ“ Input")

    # Initialize session state for examples
    if 'en_example_text' not in st.session_state:
        st.session_state.en_example_text = ""
    if 'en_example_banned' not in st.session_state:
        st.session_state.en_example_banned = ""

    # Example buttons
    st.markdown("**Examples:** Click the buttons below to load example text")
    col1, col2, col3 = st.columns(3)

    with col1:
        if st.button("Example 1: No 'E'", help="Classic lipogram avoiding the letter 'e'"):
            st.session_state.en_example_text = "The cat sat on the mat."
            st.session_state.en_example_banned = "e"

    with col2:
        if st.button("Example 2: No Vowels", help="Challenging example avoiding multiple vowels"):
            st.session_state.en_example_text = "Hello world! How are you today?"
            st.session_state.en_example_banned = "a e i o u"

    with col3:
        if st.button("Example 3: Complex", help="Complex sentence with multiple constraints"):
            st.session_state.en_example_text = "I love programming and artificial intelligence."
            st.session_state.en_example_banned = "a i"

    # Text input methods
    input_method = st.radio(
        "Input method:",
        ["Type text", "Upload file"],
        horizontal=True
    )

    input_text = ""

    if input_method == "Type text":
        input_text = st.text_area(
            "Enter your text:",
            value=st.session_state.en_example_text,
            height=150,
            placeholder="Type or paste your text here..."
        )
    else:
        uploaded_file = st.file_uploader(
            "Upload a text file:",
            type=['txt'],
            help="Upload a .txt file"
        )

        if uploaded_file is not None:
            try:
                input_text = str(uploaded_file.read(), "utf-8")
                st.text_area("File content:", value=input_text,
                             height=150, disabled=True)
            except Exception as e:
                st.error(f"Error reading file: {e}")

    # Banned characters input
    banned_chars_input = st.text_input(
        "Banned characters (space-separated):",
        value=st.session_state.en_example_banned,
        placeholder="e a i o u",
        help="Enter characters that should not appear in the output"
    )

    banned_chars = banned_chars_input.split() if banned_chars_input else []

    if banned_chars:
        st.write("**Banned characters:**")
        for char in banned_chars:
            st.code(char, language=None)

    # Quick presets
    st.write("**Quick presets:**")
    col_preset1, col_preset2 = st.columns(2)

    with col_preset1:
        if st.button("No 'E'"):
            st.session_state.en_example_banned = "e"
            st.rerun()

    with col_preset2:
        if st.button("No Vowels"):
            st.session_state.en_example_banned = "a e i o u"
            st.rerun()

    # Clear button
    if st.button("ğŸ—‘ï¸ Clear Input", help="Clear input fields"):
        st.session_state.en_example_text = ""
        st.session_state.en_example_banned = ""
        st.rerun()

    # Generate button
    if st.button("ğŸ¯ Generate Lipogram", type="primary", use_container_width=True):
        if not input_text.strip():
            st.error("âŒ Please enter some text.")
        elif not banned_chars:
            st.error("âŒ Please specify at least one banned character.")
        else:
            # Display input analysis
            display_token_analysis(input_text, banned_chars, 'English')

            # Generate lipogram
            with st.spinner("ğŸ”„ Generating lipogram..."):
                start_time = time.time()

                try:
                    if verbose_output:
                        # Capture verbose output
                        import io
                        from contextlib import redirect_stdout

                        output_buffer = io.StringIO()
                        with redirect_stdout(output_buffer):
                            result = st.session_state.english_rewriter.rewrite_text(
                                input_text, banned_chars, similarity_threshold, verbose=True
                            )

                        verbose_text = output_buffer.getvalue()
                    else:
                        result = st.session_state.english_rewriter.rewrite_text(
                            input_text, banned_chars, similarity_threshold, verbose=False
                        )
                        verbose_text = ""

                    processing_time = time.time() - start_time

                    # Display results
                    st.header("âœ¨ Generated Lipogram")

                    # Result text
                    st.text_area(
                        "Result:",
                        value=result,
                        height=150,
                        help="Generated lipogram text"
                    )

                    # Verification
                    is_valid, banned_found = verify_lipogram(
                        result, banned_chars)

                    col_result1, col_result2, col_result3 = st.columns(3)

                    with col_result1:
                        if is_valid:
                            st.success("âœ… Valid lipogram!")
                        else:
                            st.error(
                                f"âŒ Contains banned chars: {', '.join(banned_found)}")

                    with col_result2:
                        st.info(f"â±ï¸ Processing time: {processing_time:.2f}s")

                    with col_result3:
                        st.info(
                            f"ğŸ“Š Similarity threshold: {similarity_threshold}")

                    # Verbose output
                    if verbose_output and verbose_text:
                        with st.expander("ğŸ” Detailed Processing Log", expanded=False):
                            st.text(verbose_text)

                    # Download button
                    st.download_button(
                        label="ğŸ’¾ Download Result",
                        data=result,
                        file_name="lipogram_result.txt",
                        mime="text/plain"
                    )

                    # Add to history
                    st.session_state.history.append({
                        'language': 'English',
                        'input': input_text,
                        'banned_chars': banned_chars,
                        'result': result,
                        'is_valid': is_valid,
                        'processing_time': processing_time,
                        'similarity_threshold': similarity_threshold
                    })

                except Exception as e:
                    st.error(f"âŒ Error generating lipogram: {e}")
                    st.error("Please check your input and try again.")


def history_page():
    """History page showing generation history."""
    st.title("ğŸ“š Generation History")
    st.markdown(
        "View your previous lipogram generations from both Japanese and English modes.")

    if not st.session_state.history:
        st.info(
            "ğŸ“ No generation history yet. Generate some lipograms to see them here!")
        return

    # Filter options
    col1, col2 = st.columns(2)

    with col1:
        language_filter = st.selectbox(
            "Filter by language:",
            ["All", "Japanese", "English"]
        )

    with col2:
        if st.button("ğŸ—‘ï¸ Clear All History"):
            st.session_state.history = []
            st.rerun()

    # Filter history
    filtered_history = st.session_state.history
    if language_filter != "All":
        filtered_history = [
            entry for entry in st.session_state.history if entry['language'] == language_filter]

    st.write(f"**Showing {len(filtered_history)} entries**")

    # Display history
    for i, entry in enumerate(reversed(filtered_history), 1):
        with st.expander(f"{entry['language']} Generation #{len(filtered_history) - i + 1}"):
            col_hist1, col_hist2 = st.columns(2)

            with col_hist1:
                st.write("**Input:**")
                st.text(
                    entry['input'][:200] + "..." if len(entry['input']) > 200 else entry['input'])

                st.write("**Banned characters:**")
                st.code(", ".join(entry['banned_chars']))

            with col_hist2:
                st.write("**Result:**")
                st.text(
                    entry['result'][:200] + "..." if len(entry['result']) > 200 else entry['result'])

                if entry['language'] == 'Japanese':
                    st.write(f"**Model:** {entry.get('model', 'Unknown')}")
                else:
                    status = "âœ… Valid" if entry.get(
                        'is_valid', False) else "âŒ Invalid"
                    st.write(f"**Status:** {status}")
                    st.write(
                        f"**Time:** {entry.get('processing_time', 0):.2f}s")
                    st.write(
                        f"**Threshold:** {entry.get('similarity_threshold', 0):.1f}")


def main():
    """Main Streamlit application."""
    initialize_session_state()

    # Check imports
    if not IMPORTS_AVAILABLE:
        st.error(f"âŒ Import Error: {IMPORT_ERROR}")
        st.error("Please make sure all dependencies are installed.")
        st.info("Run: pip install -r requirements.txt")
        st.stop()

    # Check if PDF slideshow should be displayed
    if st.session_state.show_pdf_slideshow:
        show_pdf_slideshow()
        return

    # Sidebar navigation
    with st.sidebar:
        st.title("ğŸŒ Navigation")

        # Page selection
        page_options = ["ğŸ“ Japanese", "ğŸ¯ English", "ğŸ“š History", "ğŸ“ Research"]
        selected_page = st.radio("Select Page:", page_options)

        # Update current page
        if selected_page == "ğŸ“ Japanese":
            st.session_state.current_page = 'Japanese'
        elif selected_page == "ğŸ¯ English":
            st.session_state.current_page = 'English'
        elif selected_page == "ğŸ“š History":
            st.session_state.current_page = 'History'
        elif selected_page == "ğŸ“ Research":
            st.session_state.show_pdf_slideshow = True
            st.rerun()

        st.markdown("---")

        # Quick stats
        if st.session_state.history:
            st.markdown("**Quick Stats:**")
            japanese_count = len(
                [h for h in st.session_state.history if h['language'] == 'Japanese'])
            english_count = len(
                [h for h in st.session_state.history if h['language'] == 'English'])
            st.write(f"ğŸ‡¯ğŸ‡µ Japanese: {japanese_count}")
            st.write(f"ğŸ‡ºğŸ‡¸ English: {english_count}")
            st.write(f"ğŸ“Š Total: {len(st.session_state.history)}")

    # Main content area
    if st.session_state.current_page == 'Japanese':
        japanese_page()
    elif st.session_state.current_page == 'English':
        english_page()
    elif st.session_state.current_page == 'History':
        history_page()

    # Footer
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: gray;'>
    <p>ğŸŒ çµ±åˆãƒªãƒã‚°ãƒ©ãƒ ç”Ÿæˆå™¨ | æ—¥æœ¬èª: OpenAI GPT-4 | English: BERT + WordNet</p>
    <p>Based on research in constraint-based text generation</p>
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()
